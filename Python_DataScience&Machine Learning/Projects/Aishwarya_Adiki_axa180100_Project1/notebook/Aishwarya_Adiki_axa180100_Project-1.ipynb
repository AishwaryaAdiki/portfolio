{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ad39a5f",
   "metadata": {},
   "source": [
    "# Project 1_Aishwarya_Adiki_axa180100_AnalyzingSBADataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7a4d90",
   "metadata": {},
   "source": [
    "### Deliverables in a single zip file in the following structure:\n",
    "- `notebook` (folder)\n",
    "    - Jupyter notebook with complete code to manipulate data, train and tune final model. `ipynb` format.\n",
    "    - Jupyter notebook with scoring function. `ipynb` format.\n",
    "- `artifacts` (folder)\n",
    "    - Model and any potential encoders in the \"pkl\" format or native H2O-3 format (for H2O-3 model)\n",
    "    - Scoring function that will load the final model and encoders. Separate from above notebook or `.py` file\n",
    "\n",
    "\n",
    "\n",
    "Your notebook should include explanations about your code and be designed to be easily followed and results replicated. Once you are done with the final version, you will need to test it by running all cells from top to bottom after restarting Kernel. It can be done by running `Kernel -> Restart & Run All`\n",
    "\n",
    "\n",
    "**Important**: To speed up progress, first produce working code using a small subset of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "624505ad-5f7f-4128-9b91-22d7c7f5858f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting category_encoders==2.6.0\n",
      "  Downloading category_encoders-2.6.0-py2.py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/anaconda3/lib/python3.11/site-packages (from category_encoders==2.6.0) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/anaconda3/lib/python3.11/site-packages (from category_encoders==2.6.0) (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from category_encoders==2.6.0) (1.11.4)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from category_encoders==2.6.0) (0.14.0)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /opt/anaconda3/lib/python3.11/site-packages (from category_encoders==2.6.0) (2.1.4)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /opt/anaconda3/lib/python3.11/site-packages (from category_encoders==2.6.0) (0.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.5->category_encoders==2.6.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.5->category_encoders==2.6.0) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.5->category_encoders==2.6.0) (2023.3)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.11/site-packages (from patsy>=0.5.1->category_encoders==2.6.0) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.20.0->category_encoders==2.6.0) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.20.0->category_encoders==2.6.0) (2.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/anaconda3/lib/python3.11/site-packages (from statsmodels>=0.9.0->category_encoders==2.6.0) (23.1)\n",
      "Downloading category_encoders-2.6.0-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: category_encoders\n",
      "  Attempting uninstall: category_encoders\n",
      "    Found existing installation: category-encoders 2.6.3\n",
      "    Uninstalling category-encoders-2.6.3:\n",
      "      Successfully uninstalled category-encoders-2.6.3\n",
      "Successfully installed category_encoders-2.6.0\n",
      "Requirement already satisfied: pandoc in /opt/anaconda3/lib/python3.11/site-packages (2.3)\n",
      "Requirement already satisfied: plumbum in /opt/anaconda3/lib/python3.11/site-packages (from pandoc) (1.8.2)\n",
      "Requirement already satisfied: ply in /opt/anaconda3/lib/python3.11/site-packages (from pandoc) (3.11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 1500)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Extend cell width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "!pip install category_encoders==2.6.0\n",
    "!pip install pandoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef1cdabc-cc4e-4e69-bccc-cb2f6e63b8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /opt/anaconda3/lib/python3.11/site-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/anaconda3/lib/python3.11/site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6968be70-5b26-4860-9778-507e0e7b356e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in /opt/anaconda3/lib/python3.11/site-packages (2.6.0)\n",
      "Collecting category_encoders\n",
      "  Downloading category_encoders-2.6.3-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/anaconda3/lib/python3.11/site-packages (from category_encoders) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/anaconda3/lib/python3.11/site-packages (from category_encoders) (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from category_encoders) (1.11.4)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from category_encoders) (0.14.0)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /opt/anaconda3/lib/python3.11/site-packages (from category_encoders) (2.1.4)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /opt/anaconda3/lib/python3.11/site-packages (from category_encoders) (0.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.5->category_encoders) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.5->category_encoders) (2023.3)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.11/site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.20.0->category_encoders) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.20.0->category_encoders) (2.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/anaconda3/lib/python3.11/site-packages (from statsmodels>=0.9.0->category_encoders) (23.1)\n",
      "Downloading category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: category_encoders\n",
      "  Attempting uninstall: category_encoders\n",
      "    Found existing installation: category-encoders 2.6.0\n",
      "    Uninstalling category-encoders-2.6.0:\n",
      "      Successfully uninstalled category-encoders-2.6.0\n",
      "Successfully installed category_encoders-2.6.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade category_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe1af41",
   "metadata": {},
   "source": [
    "### Dataset preparation and clean-up\n",
    "\n",
    "Modify and clean-up the dataset as following:\n",
    "- Replace encode Na/Null values\n",
    "- Convert the strings to floats/integers as needed\n",
    "\n",
    "Any additional clean-up as you find fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f9f9eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sba  = pd.read_csv('SBA_loans_project_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0da7f6c-1c3d-4a63-89d5-1673d2b374f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sba = df_sba.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dbd820-12fc-4e9a-b4c6-423958769d57",
   "metadata": {},
   "source": [
    "#### Now I will Replace encode Na/Null values and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d0b80bf-d4cb-4afb-8dd9-0dba78ee6dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns=df_sba.select_dtypes(include=['object']).columns\n",
    "df_sba[categorical_columns]=df_sba[categorical_columns].fillna('Missing')\n",
    "df_sba=df_sba.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f21dcf",
   "metadata": {},
   "source": [
    "### Categorical and numerical variables encoding\n",
    "\n",
    "Encode categorical variables using either one of the techniques below. Don't use LabelEncoder.\n",
    "- One-hot-encoder for variables with less than 10 valid values. Name your new columns \"Original_name\"_valid_value. If you drop one of the columns, make it clear what valid value is reference value.\n",
    "- Target encoder from the following library: https://contrib.scikit-learn.org/category_encoders/index.html . Name your new column \"Original_name\"_trg\n",
    "- WOE encoder from the following library: https://contrib.scikit-learn.org/category_encoders/index.html . Name your new column \"Original_name\"_woe\n",
    "\n",
    "\n",
    "WOE encoder can be used with numerical variables too. \n",
    "\n",
    "\n",
    "Example of use for target encoder:\n",
    "```\n",
    "import category_encoders as ce\n",
    "\n",
    "encoder = ce.TargetEncoder(cols=[...])\n",
    "\n",
    "encoder.fit(X, y)\n",
    "X_cleaned = encoder.transform(X_dirty)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dc8d00-09c3-4ff5-ac6a-a1ed71480d82",
   "metadata": {},
   "source": [
    "## USING 'MIS_Status' as the target column because there's only 2 levels (0 or 1) which would work nicely for the data we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "942f7eda-403e-4d2a-85cc-9e9f986722b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BankState</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>LowDoc</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>GrAppv</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>MIS_Status</th>\n",
       "      <th>City_trg</th>\n",
       "      <th>State_trg</th>\n",
       "      <th>Bank_trg</th>\n",
       "      <th>BankState_trg</th>\n",
       "      <th>RevLineCr_trg</th>\n",
       "      <th>LowDoc_trg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APPLETON</td>\n",
       "      <td>WI</td>\n",
       "      <td>59414</td>\n",
       "      <td>ASSOCIATED BANK NATL ASSOC</td>\n",
       "      <td>WI</td>\n",
       "      <td>321918</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.085349</td>\n",
       "      <td>0.119504</td>\n",
       "      <td>0.111863</td>\n",
       "      <td>0.116801</td>\n",
       "      <td>0.149026</td>\n",
       "      <td>0.186555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WEATHERFORD</td>\n",
       "      <td>TX</td>\n",
       "      <td>76086</td>\n",
       "      <td>REGIONS BANK</td>\n",
       "      <td>AL</td>\n",
       "      <td>621391</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>146200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146200.0</td>\n",
       "      <td>124270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.137056</td>\n",
       "      <td>0.188210</td>\n",
       "      <td>0.083090</td>\n",
       "      <td>0.130599</td>\n",
       "      <td>0.146095</td>\n",
       "      <td>0.186555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FLORENCE</td>\n",
       "      <td>SC</td>\n",
       "      <td>29505</td>\n",
       "      <td>SUPERIOR FINANCIAL GROUP, LLC</td>\n",
       "      <td>CA</td>\n",
       "      <td>236220</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.173653</td>\n",
       "      <td>0.204237</td>\n",
       "      <td>0.726289</td>\n",
       "      <td>0.220324</td>\n",
       "      <td>0.146095</td>\n",
       "      <td>0.186555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOSTON</td>\n",
       "      <td>MA</td>\n",
       "      <td>2124</td>\n",
       "      <td>CITIZENS BANK NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>236115</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>73100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>37500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.129880</td>\n",
       "      <td>0.128439</td>\n",
       "      <td>0.214448</td>\n",
       "      <td>0.197587</td>\n",
       "      <td>0.146095</td>\n",
       "      <td>0.186555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LAFAYETTE</td>\n",
       "      <td>IN</td>\n",
       "      <td>47904</td>\n",
       "      <td>THE HUNTINGTON NATIONAL BANK</td>\n",
       "      <td>OH</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>64000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125934</td>\n",
       "      <td>0.174321</td>\n",
       "      <td>0.132007</td>\n",
       "      <td>0.158100</td>\n",
       "      <td>0.146095</td>\n",
       "      <td>0.089696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800250</th>\n",
       "      <td>FAIRFIELD</td>\n",
       "      <td>OH</td>\n",
       "      <td>45014</td>\n",
       "      <td>ACCESS BUS. DEVEL &amp; FINANCE IN</td>\n",
       "      <td>OH</td>\n",
       "      <td>235920</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.168250</td>\n",
       "      <td>0.163359</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.158100</td>\n",
       "      <td>0.146095</td>\n",
       "      <td>0.186555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800251</th>\n",
       "      <td>COHOES</td>\n",
       "      <td>NY</td>\n",
       "      <td>12047</td>\n",
       "      <td>EMPIRE ST. CERT. DEVEL CORP</td>\n",
       "      <td>NY</td>\n",
       "      <td>541430</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>198000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198000.0</td>\n",
       "      <td>198000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113292</td>\n",
       "      <td>0.198622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.168238</td>\n",
       "      <td>0.149026</td>\n",
       "      <td>0.186555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800252</th>\n",
       "      <td>MANSFIELD</td>\n",
       "      <td>MA</td>\n",
       "      <td>2048</td>\n",
       "      <td>BANK OF AMERICA NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>722320</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.179039</td>\n",
       "      <td>0.128439</td>\n",
       "      <td>0.275751</td>\n",
       "      <td>0.197587</td>\n",
       "      <td>0.149026</td>\n",
       "      <td>0.186555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800253</th>\n",
       "      <td>WALLINGTON</td>\n",
       "      <td>NJ</td>\n",
       "      <td>7057</td>\n",
       "      <td>VALLEY NATIONAL BANK</td>\n",
       "      <td>NJ</td>\n",
       "      <td>447110</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>520000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>520000.0</td>\n",
       "      <td>390000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.214340</td>\n",
       "      <td>0.201609</td>\n",
       "      <td>0.125518</td>\n",
       "      <td>0.091147</td>\n",
       "      <td>0.149026</td>\n",
       "      <td>0.186555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800254</th>\n",
       "      <td>CLEVELAND</td>\n",
       "      <td>OH</td>\n",
       "      <td>44115</td>\n",
       "      <td>UNITED MIDWEST SAVINGS BANK</td>\n",
       "      <td>OH</td>\n",
       "      <td>722110</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>384750.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.183901</td>\n",
       "      <td>0.163359</td>\n",
       "      <td>0.097352</td>\n",
       "      <td>0.158100</td>\n",
       "      <td>0.146095</td>\n",
       "      <td>0.186555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800255 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               City State    Zip                            Bank BankState  \\\n",
       "0          APPLETON    WI  59414      ASSOCIATED BANK NATL ASSOC        WI   \n",
       "1       WEATHERFORD    TX  76086                    REGIONS BANK        AL   \n",
       "2          FLORENCE    SC  29505   SUPERIOR FINANCIAL GROUP, LLC        CA   \n",
       "3            BOSTON    MA   2124        CITIZENS BANK NATL ASSOC        RI   \n",
       "4         LAFAYETTE    IN  47904    THE HUNTINGTON NATIONAL BANK        OH   \n",
       "...             ...   ...    ...                             ...       ...   \n",
       "800250    FAIRFIELD    OH  45014  ACCESS BUS. DEVEL & FINANCE IN        OH   \n",
       "800251       COHOES    NY  12047     EMPIRE ST. CERT. DEVEL CORP        NY   \n",
       "800252    MANSFIELD    MA   2048      BANK OF AMERICA NATL ASSOC        RI   \n",
       "800253   WALLINGTON    NJ   7057            VALLEY NATIONAL BANK        NJ   \n",
       "800254    CLEVELAND    OH  44115     UNITED MIDWEST SAVINGS BANK        OH   \n",
       "\n",
       "         NAICS  NoEmp  NewExist  CreateJob  RetainedJob  FranchiseCode  \\\n",
       "0       321918     26       1.0          0            0              1   \n",
       "1       621391      2       1.0          1            3              0   \n",
       "2       236220      3       1.0          3            3              0   \n",
       "3       236115      5       1.0          0            5              1   \n",
       "4            0     82       1.0          0            0              1   \n",
       "...        ...    ...       ...        ...          ...            ...   \n",
       "800250  235920      3       1.0          5            0              1   \n",
       "800251  541430     10       1.0          0            1              1   \n",
       "800252  722320      3       1.0          0            3              1   \n",
       "800253  447110      3       1.0          3            3              1   \n",
       "800254  722110     47       1.0          0            0              1   \n",
       "\n",
       "        UrbanRural RevLineCr LowDoc  DisbursementGross  BalanceGross  \\\n",
       "0                0         0      N           100000.0           0.0   \n",
       "1                1         N      N           146200.0           0.0   \n",
       "2                1         N      N            20000.0           0.0   \n",
       "3                1         N      N            73100.0           0.0   \n",
       "4                0         N      Y            80000.0           0.0   \n",
       "...            ...       ...    ...                ...           ...   \n",
       "800250           0         N      N           145000.0           0.0   \n",
       "800251           1         0      N           198000.0           0.0   \n",
       "800252           1         0      N            10000.0           0.0   \n",
       "800253           1         0      N           520000.0           0.0   \n",
       "800254           1         N      N           513000.0           0.0   \n",
       "\n",
       "          GrAppv  SBA_Appv  MIS_Status  City_trg  State_trg  Bank_trg  \\\n",
       "0       100000.0   80000.0           0  0.085349   0.119504  0.111863   \n",
       "1       146200.0  124270.0           0  0.137056   0.188210  0.083090   \n",
       "2        20000.0   17000.0           1  0.173653   0.204237  0.726289   \n",
       "3        75000.0   37500.0           1  0.129880   0.128439  0.214448   \n",
       "4        80000.0   64000.0           0  0.125934   0.174321  0.132007   \n",
       "...          ...       ...         ...       ...        ...       ...   \n",
       "800250  145000.0  145000.0           0  0.168250   0.163359  0.000001   \n",
       "800251  198000.0  198000.0           0  0.113292   0.198622  0.000000   \n",
       "800252   10000.0    5000.0           1  0.179039   0.128439  0.275751   \n",
       "800253  520000.0  390000.0           0  0.214340   0.201609  0.125518   \n",
       "800254  513000.0  384750.0           0  0.183901   0.163359  0.097352   \n",
       "\n",
       "        BankState_trg  RevLineCr_trg  LowDoc_trg  \n",
       "0            0.116801       0.149026    0.186555  \n",
       "1            0.130599       0.146095    0.186555  \n",
       "2            0.220324       0.146095    0.186555  \n",
       "3            0.197587       0.146095    0.186555  \n",
       "4            0.158100       0.146095    0.089696  \n",
       "...               ...            ...         ...  \n",
       "800250       0.158100       0.146095    0.186555  \n",
       "800251       0.168238       0.149026    0.186555  \n",
       "800252       0.197587       0.149026    0.186555  \n",
       "800253       0.091147       0.149026    0.186555  \n",
       "800254       0.158100       0.146095    0.186555  \n",
       "\n",
       "[800255 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import category_encoders as ce \n",
    "\n",
    "# Defining Target Encoder\n",
    "target_encoder=ce.TargetEncoder(cols=categorical_columns)\n",
    "\n",
    "# Fitting Target Encoder on dataset\n",
    "target_encoder.fit(df_sba[categorical_columns],df_sba['MIS_Status']) \n",
    "# Transforming dataset\n",
    "df_sba_transformed = df_sba.join(target_encoder.transform(df_sba[categorical_columns]), lsuffix='', rsuffix='_trg')\n",
    "\n",
    "display(df_sba_transformed) #Originalname_trg columns appended to the very right of the data frame, so please scroll to the far right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2636e0e6-5dbb-4b27-a98b-0e7335893a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sba_transformed = df_sba_transformed.drop(columns=['Zip', 'NAICS', 'NoEmp', 'NewExist', 'CreateJob', 'RetainedJob',\n",
    "       'FranchiseCode', 'UrbanRural', 'DisbursementGross', 'BalanceGross',\n",
    "       'GrAppv', 'SBA_Appv','City', 'State', 'Bank', 'BankState', 'RevLineCr', 'LowDoc' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87f87e7-1008-4a7b-aff4-3e7233e60c1a",
   "metadata": {},
   "source": [
    "## STANDARD SCALER: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1431ee15-ee82-46d6-b3e9-0b5a12dc8916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Zip', 'NAICS', 'NoEmp', 'NewExist', 'CreateJob', 'RetainedJob',\n",
       "       'FranchiseCode', 'UrbanRural', 'DisbursementGross', 'BalanceGross',\n",
       "       'GrAppv', 'SBA_Appv', 'MIS_Status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "num_cols = df_sba.select_dtypes(include = np.number).columns\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c47f1c7-154d-41da-ab5e-ce8a82eac916",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MIS_Status</th>\n",
       "      <th>City_trg</th>\n",
       "      <th>State_trg</th>\n",
       "      <th>Bank_trg</th>\n",
       "      <th>BankState_trg</th>\n",
       "      <th>RevLineCr_trg</th>\n",
       "      <th>LowDoc_trg</th>\n",
       "      <th>Zip</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>GrAppv</th>\n",
       "      <th>SBA_Appv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.085349</td>\n",
       "      <td>0.119504</td>\n",
       "      <td>0.111863</td>\n",
       "      <td>0.116801</td>\n",
       "      <td>0.149026</td>\n",
       "      <td>0.186555</td>\n",
       "      <td>0.180316</td>\n",
       "      <td>-0.290953</td>\n",
       "      <td>0.193751</td>\n",
       "      <td>-0.620218</td>\n",
       "      <td>-0.035640</td>\n",
       "      <td>-0.045517</td>\n",
       "      <td>-0.215971</td>\n",
       "      <td>-1.172094</td>\n",
       "      <td>-0.351298</td>\n",
       "      <td>-0.002135</td>\n",
       "      <td>-0.327034</td>\n",
       "      <td>-0.304182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.137056</td>\n",
       "      <td>0.188210</td>\n",
       "      <td>0.083090</td>\n",
       "      <td>0.130599</td>\n",
       "      <td>0.146095</td>\n",
       "      <td>0.186555</td>\n",
       "      <td>0.714821</td>\n",
       "      <td>0.846463</td>\n",
       "      <td>-0.125393</td>\n",
       "      <td>-0.620218</td>\n",
       "      <td>-0.031424</td>\n",
       "      <td>-0.032884</td>\n",
       "      <td>-0.216049</td>\n",
       "      <td>0.374585</td>\n",
       "      <td>-0.190561</td>\n",
       "      <td>-0.002135</td>\n",
       "      <td>-0.163734</td>\n",
       "      <td>-0.109982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.173653</td>\n",
       "      <td>0.204237</td>\n",
       "      <td>0.726289</td>\n",
       "      <td>0.220324</td>\n",
       "      <td>0.146095</td>\n",
       "      <td>0.186555</td>\n",
       "      <td>-0.778569</td>\n",
       "      <td>-0.616438</td>\n",
       "      <td>-0.112096</td>\n",
       "      <td>-0.620218</td>\n",
       "      <td>-0.022991</td>\n",
       "      <td>-0.032884</td>\n",
       "      <td>-0.216049</td>\n",
       "      <td>0.374585</td>\n",
       "      <td>-0.629631</td>\n",
       "      <td>-0.002135</td>\n",
       "      <td>-0.609804</td>\n",
       "      <td>-0.580546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.129880</td>\n",
       "      <td>0.128439</td>\n",
       "      <td>0.214448</td>\n",
       "      <td>0.197587</td>\n",
       "      <td>0.146095</td>\n",
       "      <td>0.186555</td>\n",
       "      <td>-1.656405</td>\n",
       "      <td>-0.616837</td>\n",
       "      <td>-0.085500</td>\n",
       "      <td>-0.620218</td>\n",
       "      <td>-0.035640</td>\n",
       "      <td>-0.024461</td>\n",
       "      <td>-0.215971</td>\n",
       "      <td>0.374585</td>\n",
       "      <td>-0.444888</td>\n",
       "      <td>-0.002135</td>\n",
       "      <td>-0.415400</td>\n",
       "      <td>-0.490618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.125934</td>\n",
       "      <td>0.174321</td>\n",
       "      <td>0.132007</td>\n",
       "      <td>0.158100</td>\n",
       "      <td>0.146095</td>\n",
       "      <td>0.089696</td>\n",
       "      <td>-0.188696</td>\n",
       "      <td>-1.513615</td>\n",
       "      <td>0.938422</td>\n",
       "      <td>-0.620218</td>\n",
       "      <td>-0.035640</td>\n",
       "      <td>-0.045517</td>\n",
       "      <td>-0.215971</td>\n",
       "      <td>-1.172094</td>\n",
       "      <td>-0.420881</td>\n",
       "      <td>-0.002135</td>\n",
       "      <td>-0.397727</td>\n",
       "      <td>-0.374370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800250</th>\n",
       "      <td>0</td>\n",
       "      <td>0.168250</td>\n",
       "      <td>0.163359</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.158100</td>\n",
       "      <td>0.146095</td>\n",
       "      <td>0.186555</td>\n",
       "      <td>-0.281349</td>\n",
       "      <td>-0.617578</td>\n",
       "      <td>-0.112096</td>\n",
       "      <td>-0.620218</td>\n",
       "      <td>-0.014558</td>\n",
       "      <td>-0.045517</td>\n",
       "      <td>-0.215971</td>\n",
       "      <td>-1.172094</td>\n",
       "      <td>-0.194736</td>\n",
       "      <td>-0.002135</td>\n",
       "      <td>-0.167976</td>\n",
       "      <td>-0.019045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800251</th>\n",
       "      <td>0</td>\n",
       "      <td>0.113292</td>\n",
       "      <td>0.198622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.168238</td>\n",
       "      <td>0.149026</td>\n",
       "      <td>0.186555</td>\n",
       "      <td>-1.338273</td>\n",
       "      <td>0.542766</td>\n",
       "      <td>-0.019012</td>\n",
       "      <td>-0.620218</td>\n",
       "      <td>-0.035640</td>\n",
       "      <td>-0.041306</td>\n",
       "      <td>-0.215971</td>\n",
       "      <td>0.374585</td>\n",
       "      <td>-0.010341</td>\n",
       "      <td>-0.002135</td>\n",
       "      <td>0.019359</td>\n",
       "      <td>0.213452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800252</th>\n",
       "      <td>1</td>\n",
       "      <td>0.179039</td>\n",
       "      <td>0.128439</td>\n",
       "      <td>0.275751</td>\n",
       "      <td>0.197587</td>\n",
       "      <td>0.149026</td>\n",
       "      <td>0.186555</td>\n",
       "      <td>-1.658842</td>\n",
       "      <td>1.229797</td>\n",
       "      <td>-0.112096</td>\n",
       "      <td>-0.620218</td>\n",
       "      <td>-0.035640</td>\n",
       "      <td>-0.032884</td>\n",
       "      <td>-0.215971</td>\n",
       "      <td>0.374585</td>\n",
       "      <td>-0.664422</td>\n",
       "      <td>-0.002135</td>\n",
       "      <td>-0.645150</td>\n",
       "      <td>-0.633187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800253</th>\n",
       "      <td>0</td>\n",
       "      <td>0.214340</td>\n",
       "      <td>0.201609</td>\n",
       "      <td>0.125518</td>\n",
       "      <td>0.091147</td>\n",
       "      <td>0.149026</td>\n",
       "      <td>0.186555</td>\n",
       "      <td>-1.498253</td>\n",
       "      <td>0.184534</td>\n",
       "      <td>-0.112096</td>\n",
       "      <td>-0.620218</td>\n",
       "      <td>-0.022991</td>\n",
       "      <td>-0.032884</td>\n",
       "      <td>-0.215971</td>\n",
       "      <td>0.374585</td>\n",
       "      <td>1.109946</td>\n",
       "      <td>-0.002135</td>\n",
       "      <td>1.157510</td>\n",
       "      <td>1.055704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800254</th>\n",
       "      <td>0</td>\n",
       "      <td>0.183901</td>\n",
       "      <td>0.163359</td>\n",
       "      <td>0.097352</td>\n",
       "      <td>0.158100</td>\n",
       "      <td>0.146095</td>\n",
       "      <td>0.186555</td>\n",
       "      <td>-0.310171</td>\n",
       "      <td>1.228999</td>\n",
       "      <td>0.473003</td>\n",
       "      <td>-0.620218</td>\n",
       "      <td>-0.035640</td>\n",
       "      <td>-0.045517</td>\n",
       "      <td>-0.215971</td>\n",
       "      <td>0.374585</td>\n",
       "      <td>1.085592</td>\n",
       "      <td>-0.002135</td>\n",
       "      <td>1.132767</td>\n",
       "      <td>1.032673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800255 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MIS_Status  City_trg  State_trg  Bank_trg  BankState_trg  \\\n",
       "0                0  0.085349   0.119504  0.111863       0.116801   \n",
       "1                0  0.137056   0.188210  0.083090       0.130599   \n",
       "2                1  0.173653   0.204237  0.726289       0.220324   \n",
       "3                1  0.129880   0.128439  0.214448       0.197587   \n",
       "4                0  0.125934   0.174321  0.132007       0.158100   \n",
       "...            ...       ...        ...       ...            ...   \n",
       "800250           0  0.168250   0.163359  0.000001       0.158100   \n",
       "800251           0  0.113292   0.198622  0.000000       0.168238   \n",
       "800252           1  0.179039   0.128439  0.275751       0.197587   \n",
       "800253           0  0.214340   0.201609  0.125518       0.091147   \n",
       "800254           0  0.183901   0.163359  0.097352       0.158100   \n",
       "\n",
       "        RevLineCr_trg  LowDoc_trg       Zip     NAICS     NoEmp  NewExist  \\\n",
       "0            0.149026    0.186555  0.180316 -0.290953  0.193751 -0.620218   \n",
       "1            0.146095    0.186555  0.714821  0.846463 -0.125393 -0.620218   \n",
       "2            0.146095    0.186555 -0.778569 -0.616438 -0.112096 -0.620218   \n",
       "3            0.146095    0.186555 -1.656405 -0.616837 -0.085500 -0.620218   \n",
       "4            0.146095    0.089696 -0.188696 -1.513615  0.938422 -0.620218   \n",
       "...               ...         ...       ...       ...       ...       ...   \n",
       "800250       0.146095    0.186555 -0.281349 -0.617578 -0.112096 -0.620218   \n",
       "800251       0.149026    0.186555 -1.338273  0.542766 -0.019012 -0.620218   \n",
       "800252       0.149026    0.186555 -1.658842  1.229797 -0.112096 -0.620218   \n",
       "800253       0.149026    0.186555 -1.498253  0.184534 -0.112096 -0.620218   \n",
       "800254       0.146095    0.186555 -0.310171  1.228999  0.473003 -0.620218   \n",
       "\n",
       "        CreateJob  RetainedJob  FranchiseCode  UrbanRural  DisbursementGross  \\\n",
       "0       -0.035640    -0.045517      -0.215971   -1.172094          -0.351298   \n",
       "1       -0.031424    -0.032884      -0.216049    0.374585          -0.190561   \n",
       "2       -0.022991    -0.032884      -0.216049    0.374585          -0.629631   \n",
       "3       -0.035640    -0.024461      -0.215971    0.374585          -0.444888   \n",
       "4       -0.035640    -0.045517      -0.215971   -1.172094          -0.420881   \n",
       "...           ...          ...            ...         ...                ...   \n",
       "800250  -0.014558    -0.045517      -0.215971   -1.172094          -0.194736   \n",
       "800251  -0.035640    -0.041306      -0.215971    0.374585          -0.010341   \n",
       "800252  -0.035640    -0.032884      -0.215971    0.374585          -0.664422   \n",
       "800253  -0.022991    -0.032884      -0.215971    0.374585           1.109946   \n",
       "800254  -0.035640    -0.045517      -0.215971    0.374585           1.085592   \n",
       "\n",
       "        BalanceGross    GrAppv  SBA_Appv  \n",
       "0          -0.002135 -0.327034 -0.304182  \n",
       "1          -0.002135 -0.163734 -0.109982  \n",
       "2          -0.002135 -0.609804 -0.580546  \n",
       "3          -0.002135 -0.415400 -0.490618  \n",
       "4          -0.002135 -0.397727 -0.374370  \n",
       "...              ...       ...       ...  \n",
       "800250     -0.002135 -0.167976 -0.019045  \n",
       "800251     -0.002135  0.019359  0.213452  \n",
       "800252     -0.002135 -0.645150 -0.633187  \n",
       "800253     -0.002135  1.157510  1.055704  \n",
       "800254     -0.002135  1.132767  1.032673  \n",
       "\n",
       "[800255 rows x 19 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler=StandardScaler()\n",
    "numerical_variables=['Zip', 'NAICS', 'NoEmp', 'NewExist', 'CreateJob', 'RetainedJob',\n",
    "       'FranchiseCode', 'UrbanRural', 'DisbursementGross', 'BalanceGross',\n",
    "       'GrAppv', 'SBA_Appv']\n",
    "\n",
    "StandardScaler = scaler.fit(df_sba[numerical_variables])\n",
    "\n",
    "df_sba_sca = StandardScaler.transform(df_sba[numerical_variables])\n",
    "df_sba_sca = pd.DataFrame(df_sba_sca, index=df_sba.index)\n",
    "df_sba_sca = df_sba_sca.rename(columns={0: \"Zip\", 1: \"NAICS\", 2: \"NoEmp\", 3:'NewExist', 4:'CreateJob', 5:'RetainedJob',\n",
    "       6:'FranchiseCode', 7:'UrbanRural', 8:'DisbursementGross', 9:'BalanceGross',\n",
    "       10:'GrAppv', 11:'SBA_Appv'})\n",
    "\n",
    "df_sba_transformed = df_sba_transformed.join(df_sba_sca)\n",
    "covtype_df = df_sba_transformed.copy()\n",
    "display(df_sba_transformed) ## FINAL STANDARDIZED DATAFRAME\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced690c6",
   "metadata": {},
   "source": [
    "## Model Tuning\n",
    "\n",
    "You should tune two types of models: one Sklearn and one H2O-3. Perform tuning for the selected model type from the set of Linear models available in Sklearn and H2O-3:\n",
    "- Hyper-parameter tuning. Your hyper-parameter search space should have at least 50 combinations.\n",
    "- To avoid overfitting and provide you with reasonable estimate of model performance on hold-out dataset, you will need to split your dataset as following:\n",
    "    - Train, will be used to train model\n",
    "    - Validation, will be used to validate model each round of training\n",
    "    - Testing, will be used to provide final performance metrics, used only once on the final model\n",
    "- Feature engineering. See project description\n",
    "\n",
    "**Select final model that produces best performance on the Test dataset.**\n",
    "- For the best model, calculate probability threshold to maximize F1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6badfabc-ccce-46f9-9bfe-c764ad573fc8",
   "metadata": {},
   "source": [
    "### The linear model I have selected is: logistic Regression.\n",
    "\n",
    "### Splitting data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "478f6e4c-70e5-4d6c-9757-44b7dee5ad72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "target_col = \"MIS_Status\"\n",
    "y = df_sba_transformed[target_col]\n",
    "X = df_sba_transformed.drop(columns=[target_col])\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X,y,test_size=0.4, random_state=142) # splitting into train and temp\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_temp,y_temp,test_size = 0.5, random_state=142) ## temp being split into test and validate sets\n",
    "\n",
    "X_train.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)\n",
    "X_valid.reset_index(inplace=True, drop=True)\n",
    "y_valid.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6ff506-2250-4365-babd-c3576bfada03",
   "metadata": {},
   "source": [
    "## HYPERPARAMETER TUNING: 5 X 4 X 4 X 1 = 80 COMBINATIONS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "56715d64-7d5b-41c8-aaf5-087c8c63b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, make_scorer \n",
    "import numpy as np\n",
    "# Defining the hyperparameter space\n",
    "\n",
    "param_grid = [    \n",
    "    {'penalty' : ['l2'],\n",
    "    'solver' : ['lbfgs','newton-cg','sag','saga'],\n",
    "     'C': [10, 1.0, 0.1, 0.01],\n",
    "    'max_iter' : [100, 150, 175, 200, 250]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Defining the scoring metric as F1 score\n",
    "f1_scorer = make_scorer(f1_score,average='weighted')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f4bfdc-a940-4091-99e0-7d15e81e3d5b",
   "metadata": {},
   "source": [
    "## SKLEARN MODEL: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a885579-5e59-459c-97a0-65488ad7a11b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 80 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid=[{&#x27;C&#x27;: [10, 1.0, 0.1, 0.01],\n",
       "                          &#x27;max_iter&#x27;: [100, 150, 175, 200, 250],\n",
       "                          &#x27;penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                          &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;newton-cg&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;]}],\n",
       "             verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid=[{&#x27;C&#x27;: [10, 1.0, 0.1, 0.01],\n",
       "                          &#x27;max_iter&#x27;: [100, 150, 175, 200, 250],\n",
       "                          &#x27;penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                          &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;newton-cg&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;]}],\n",
       "             verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid=[{'C': [10, 1.0, 0.1, 0.01],\n",
       "                          'max_iter': [100, 150, 175, 200, 250],\n",
       "                          'penalty': ['l2'],\n",
       "                          'solver': ['lbfgs', 'newton-cg', 'sag', 'saga']}],\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing the Linear regression model: \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "logModel = LogisticRegression()\n",
    "\n",
    "# Performing Grid Search\n",
    "grid_search = GridSearchCV(logModel, param_grid = param_grid, verbose = True, cv=2, n_jobs=-1) # pds used the validatio data set at each model\n",
    "grid_search.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910aaf01-908d-423d-bc0b-48bdc5d9ac20",
   "metadata": {},
   "source": [
    "### Please ignore the warnings above. They occur due to non convergence issues, but they are not errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "077652ae-1857-448e-91fb-4144a2956f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'max_iter': 200, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best F1 Score: 0.83486097185776\n",
      "Confusion Matrix:\n",
      "[[128691   3368]\n",
      " [ 23150   4842]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, make_scorer \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "# Getting the best model parameters \n",
    "best_params=grid_search.best_params_\n",
    "\n",
    "# Getting the best F1 score\n",
    "best_f1=grid_search.best_score_\n",
    "\n",
    "# Get the confusion matrix for the best model\n",
    "y_pred=grid_search.predict(X_test)\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Best Parameters:\",best_params)\n",
    "print(\"Best F1 Score:\",best_f1)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "97a39072-3f09-41c6-bd30-080f1207ca5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score:  0.7702116835434315\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = grid_search.predict_proba(X_test)[::,1]\n",
    "\n",
    "#calculate AUC of mode\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "#print AUC score\n",
    "print(\"AUC Score: \", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0f76dd-265a-4b0e-b7ee-de64bf9d3f37",
   "metadata": {},
   "source": [
    "#### From this we can see that the best parameters are: C value of 10, max iterations of 200, a penalty of l2, and the lbfgs solver. \n",
    "#### These parameters give us the F1 score of 0.83486. The F1 score ranges between 0 and 1, with 0 denoting the lowest possible result and 1 denoting a flawless result, meaning that the model accurately predicted each label. A high F1 score generally indicates a well-balanced performance, demonstrating that the model can concurrently attain high precision and high recall. \n",
    "#### Therefore an F1 Score of 0.83486 can be considered good\n",
    "#### Furthermore, the AUC is 0.7702, which is moderately good and feasible\n",
    "#### Probablity threshold = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "21b5f733-7a2f-4dd0-9895-cd0b5411e7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sba_transformed\n",
    "def train_model(data):\n",
    "    target_col = \"MIS_Status\"\n",
    "    cols_to_drop = ['MIS_Status']\n",
    "    y = data[target_col]\n",
    "    X = data.drop(columns=[target_col])\n",
    "    \n",
    "    threshold = 0.9\n",
    "    clf = LogisticRegression(max_iter=200, C = 10, penalty = 'l2', solver = 'lbfgs')\n",
    "    \n",
    "    columns_to_train = [x for x in X.columns if x not in cols_to_drop]\n",
    "    print(\"Training on following columns:\", columns_to_train)\n",
    "    clf.fit(X[columns_to_train], y)\n",
    "    \n",
    "    artifacts_dict = {\n",
    "        \"model\": clf,\n",
    "        \"categorical_columns\": categorical_columns,\n",
    "        \"numerical_variables\" : numerical_variables,\n",
    "        \"StandardScaler\" : StandardScaler,\n",
    "        \"columns_to_train\":columns_to_train,\n",
    "        \"target_encoder\" : target_encoder,\n",
    "        \"threshold\": threshold\n",
    "    }\n",
    "    import os\n",
    "    import sys\n",
    "    import pickle\n",
    "    projectabspathname = os.path.abspath('Aishwarya_Adiki_axa180100_Project-1.pickle')\n",
    "    projectname = 'Aishwarya_Adiki_axa180100_Project-1.ipynb'\n",
    "    projectpickle = open(str(projectabspathname),'wb')\n",
    "    pickle.dump(obj=artifacts_dict, file=projectpickle)\n",
    "    projectpickle.close()  \n",
    "    return clf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "df581112-cbb0-4ffb-a231-69b531ad165d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on following columns: ['City_trg', 'State_trg', 'Bank_trg', 'BankState_trg', 'RevLineCr_trg', 'LowDoc_trg', 'Zip', 'NAICS', 'NoEmp', 'NewExist', 'CreateJob', 'RetainedJob', 'FranchiseCode', 'UrbanRural', 'DisbursementGross', 'BalanceGross', 'GrAppv', 'SBA_Appv']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, max_iter=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, max_iter=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10, max_iter=200)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(df_sba_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e05efa88-2c7e-4cd0-8562-f28df6bccf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept  -4.64397811137711\n",
      "classes [0 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>City_trg</th>\n",
       "      <td>5.575750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State_trg</th>\n",
       "      <td>-0.556621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bank_trg</th>\n",
       "      <td>4.872677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BankState_trg</th>\n",
       "      <td>0.686155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevLineCr_trg</th>\n",
       "      <td>2.350303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowDoc_trg</th>\n",
       "      <td>2.894063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zip</th>\n",
       "      <td>0.074891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAICS</th>\n",
       "      <td>-0.008645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoEmp</th>\n",
       "      <td>-0.071180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewExist</th>\n",
       "      <td>0.077562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreateJob</th>\n",
       "      <td>0.152448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RetainedJob</th>\n",
       "      <td>-0.089102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FranchiseCode</th>\n",
       "      <td>0.025102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UrbanRural</th>\n",
       "      <td>0.300672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DisbursementGross</th>\n",
       "      <td>-0.042433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BalanceGross</th>\n",
       "      <td>-0.182576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrAppv</th>\n",
       "      <td>0.399116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SBA_Appv</th>\n",
       "      <td>-0.593787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      coeff\n",
       "City_trg           5.575750\n",
       "State_trg         -0.556621\n",
       "Bank_trg           4.872677\n",
       "BankState_trg      0.686155\n",
       "RevLineCr_trg      2.350303\n",
       "LowDoc_trg         2.894063\n",
       "Zip                0.074891\n",
       "NAICS             -0.008645\n",
       "NoEmp             -0.071180\n",
       "NewExist           0.077562\n",
       "CreateJob          0.152448\n",
       "RetainedJob       -0.089102\n",
       "FranchiseCode      0.025102\n",
       "UrbanRural         0.300672\n",
       "DisbursementGross -0.042433\n",
       "BalanceGross      -0.182576\n",
       "GrAppv             0.399116\n",
       "SBA_Appv          -0.593787"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestmodel = LogisticRegression(max_iter=200, C = 10, penalty = 'l2', solver = 'lbfgs')\n",
    "bestmodel.fit(X, y)\n",
    "print('intercept ', bestmodel.intercept_[0])\n",
    "print('classes', bestmodel.classes_)\n",
    "pd.DataFrame({'coeff': bestmodel.coef_[0]}, \n",
    "             index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "06f7da62-c450-45e0-a78f-58e99fb7ec5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City_trg: 0.007164799553475642\n",
      "State_trg: -3.040697444358272e-05\n",
      "Bank_trg: 0.01966823075144796\n",
      "BankState_trg: 9.842695973989827e-05\n",
      "RevLineCr_trg: 0.0014720724435752601\n",
      "LowDoc_trg: 0.0003583441111478828\n",
      "Zip: 0.0003506382340628685\n",
      "NAICS: -3.061524139183295e-05\n",
      "NoEmp: 1.5120180442462771e-05\n",
      "NewExist: 1.932717279697164e-05\n",
      "CreateJob: 0.0005977261414590577\n",
      "RetainedJob: 0.0003063606808662874\n",
      "FranchiseCode: 2.6574862595859135e-05\n",
      "UrbanRural: 0.001989574156570902\n",
      "DisbursementGross: 0.00012987526892468035\n",
      "BalanceGross: 2.499203378913961e-07\n",
      "GrAppv: 0.007818632810791534\n",
      "SBA_Appv: 0.00863503924790638\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import permutation_importance\n",
    "best_dtc = grid_search.best_estimator_ \n",
    "# Calculate permutation importance using the best model\n",
    "result = permutation_importance(best_dtc, X, y, n_repeats=30, random_state=42)\n",
    "\n",
    "feature_importances = result.importances_mean\n",
    "feature_names = X.columns\n",
    "\n",
    "for feature, importance in zip(feature_names, feature_importances):\n",
    "    print(f'{feature}: {importance}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9734a855-0f86-4b70-82ec-313e309f322a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 500x100 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting feature importances\n",
    "sorted_idx = feature_importances.argsort()[::-1]\n",
    "plt.bar(range(X.shape[1]), feature_importances[sorted_idx], tick_label=feature_names[sorted_idx])\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Permutation Importance')\n",
    "plt.title('Feature Importance Using Permutation Method')\n",
    "plt.figure(figsize=(5,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678bc3d8-eee7-4012-8518-c3faf63d53ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52cfb022-91d3-45df-8b3b-3ee0093da0fc",
   "metadata": {},
   "source": [
    "## H20-3 Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a6fd2a1-8dc9-4d27-a6f2-8cc3cacaa5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h2o in /opt/anaconda3/lib/python3.11/site-packages (3.46.0.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (from h2o) (2.31.0)\n",
      "Requirement already satisfied: tabulate in /opt/anaconda3/lib/python3.11/site-packages (from h2o) (0.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests->h2o) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests->h2o) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests->h2o) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests->h2o) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a3ed6ee-2abe-42b1-bcb1-072f7160d682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "365b7121-9e43-4be6-a166-cf378670165b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"17.0.7\" 2023-04-18; OpenJDK Runtime Environment Temurin-17.0.7+7 (build 17.0.7+7); OpenJDK 64-Bit Server VM Temurin-17.0.7+7 (build 17.0.7+7, mixed mode, sharing)\n",
      "  Starting server from /opt/anaconda3/lib/python3.11/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/hd/qln9g6n51snggb5qgwn55w9c0000gn/T/tmpq5pm_p3o\n",
      "  JVM stdout: /var/folders/hd/qln9g6n51snggb5qgwn55w9c0000gn/T/tmpq5pm_p3o/h2o_aishwaryaadiki_started_from_python.out\n",
      "  JVM stderr: /var/folders/hd/qln9g6n51snggb5qgwn55w9c0000gn/T/tmpq5pm_p3o/h2o_aishwaryaadiki_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/Chicago</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.1</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>12 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_aishwaryaadiki_1fcysx</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>4 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>10</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>10</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.11.7 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -------------------------------------\n",
       "H2O_cluster_uptime:         02 secs\n",
       "H2O_cluster_timezone:       America/Chicago\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.1\n",
       "H2O_cluster_version_age:    12 days\n",
       "H2O_cluster_name:           H2O_from_python_aishwaryaadiki_1fcysx\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    4 Gb\n",
       "H2O_cluster_total_cores:    10\n",
       "H2O_cluster_allowed_cores:  10\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.11.7 final\n",
       "--------------------------  -------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32212e55-15c9-457a-b726-67342fcd4166",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_h2o = X_train.join(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "420e3585-f452-4807-998c-a5caa615fb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "X_train_h2o = h2o.H2OFrame(X_train_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3be6fc6-5410-491f-9e8d-ca229b782a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "X_test_h2o = X_test.join(y_test)\n",
    "X_test_h2o = h2o.H2OFrame(X_test_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dd1a248-6b38-43dd-ad25-cd8abfb6731d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "X_valid_h2o = X_valid.join(y_valid)\n",
    "X_valid_h2o = h2o.H2OFrame(X_valid_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13d7d7b9-b3c8-4c14-bc52-087d24ca7bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = \"MIS_Status\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0dc2aaab-b57e-480a-9ead-d4f31f804e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "from h2o.grid import H2OGridSearch\n",
    "alpha_list = [0.05,0.1,0.2,0.3,0.4, 0.5, 0.6, 0.7, 0.9]\n",
    "lambda_list = [0.1, 0.2,0.3,0.4,0.5]\n",
    "glm_hyper_params = { 'alpha': [0.05,0.1,0.2,0.3,0.4, 0.5, 0.6, 0.7, 0.9], \n",
    "                     'lambda': [0.1,0.05,0.01, 0.2,0.3,0.4,0.5]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04af0a6c-c6fe-43fc-9d65-992164328281",
   "metadata": {},
   "source": [
    "### 9 alpha values and 7 lambda values = 63 combinations for hyperparameters ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74522f86-63ea-4caa-b9e4-e084f54d3c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_criteria = { 'strategy': \"RandomDiscrete\", \n",
    "                    'seed': 142,\n",
    "                    'stopping_metric': \"AUC\", \n",
    "                    'stopping_tolerance': 0.01,\n",
    "                    'stopping_rounds': 5 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e35cccab-1010-4131-9339-cd8aabd20827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor columns: ['City_trg', 'State_trg', 'Bank_trg', 'BankState_trg', 'RevLineCr_trg', 'LowDoc_trg', 'Zip', 'NAICS', 'NoEmp', 'NewExist', 'CreateJob', 'RetainedJob', 'FranchiseCode', 'UrbanRural', 'DisbursementGross', 'BalanceGross', 'GrAppv', 'SBA_Appv']\n",
      "Respomse columns: MIS_Status\n"
     ]
    }
   ],
   "source": [
    "#Prepare predictors and response columns\n",
    "predictors = X_train_h2o.columns\n",
    "predictors.remove(\"MIS_Status\")\n",
    "print(\"Predictor columns:\", predictors)\n",
    "print(\"Respomse columns:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c120ed68-aa36-406c-8e61-3038ed835913",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Grid Build progress: |███████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Hyper-Parameter Search Summary: ordered by increasing logloss</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>alpha</th>\n",
       "<th>lambda</th>\n",
       "<th>model_ids</th>\n",
       "<th>logloss</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>0.05</td>\n",
       "<td>0.01</td>\n",
       "<td>SBAloans_glm_grid7_model_4</td>\n",
       "<td>0.3930122</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.1</td>\n",
       "<td>0.01</td>\n",
       "<td>SBAloans_glm_grid7_model_2</td>\n",
       "<td>0.3931789</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.7</td>\n",
       "<td>0.01</td>\n",
       "<td>SBAloans_glm_grid7_model_7</td>\n",
       "<td>0.3967745</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.9</td>\n",
       "<td>0.01</td>\n",
       "<td>SBAloans_glm_grid7_model_15</td>\n",
       "<td>0.3981886</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.05</td>\n",
       "<td>0.05</td>\n",
       "<td>SBAloans_glm_grid7_model_6</td>\n",
       "<td>0.4008775</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.1</td>\n",
       "<td>0.05</td>\n",
       "<td>SBAloans_glm_grid7_model_16</td>\n",
       "<td>0.4027881</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.05</td>\n",
       "<td>0.1</td>\n",
       "<td>SBAloans_glm_grid7_model_12</td>\n",
       "<td>0.4106207</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.5</td>\n",
       "<td>0.05</td>\n",
       "<td>SBAloans_glm_grid7_model_17</td>\n",
       "<td>0.4240252</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.05</td>\n",
       "<td>0.3</td>\n",
       "<td>SBAloans_glm_grid7_model_10</td>\n",
       "<td>0.4380749</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.4</td>\n",
       "<td>0.1</td>\n",
       "<td>SBAloans_glm_grid7_model_1</td>\n",
       "<td>0.4453240</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.05</td>\n",
       "<td>0.4</td>\n",
       "<td>SBAloans_glm_grid7_model_13</td>\n",
       "<td>0.4463526</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.2</td>\n",
       "<td>0.2</td>\n",
       "<td>SBAloans_glm_grid7_model_9</td>\n",
       "<td>0.4525951</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.1</td>\n",
       "<td>0.4</td>\n",
       "<td>SBAloans_glm_grid7_model_8</td>\n",
       "<td>0.4576421</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.3</td>\n",
       "<td>0.4</td>\n",
       "<td>SBAloans_glm_grid7_model_11</td>\n",
       "<td>0.4640820</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.5</td>\n",
       "<td>0.4</td>\n",
       "<td>SBAloans_glm_grid7_model_14</td>\n",
       "<td>0.4640820</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.9</td>\n",
       "<td>0.4</td>\n",
       "<td>SBAloans_glm_grid7_model_3</td>\n",
       "<td>0.4640820</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.4</td>\n",
       "<td>0.2</td>\n",
       "<td>SBAloans_glm_grid7_model_5</td>\n",
       "<td>0.4640820</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "Hyper-Parameter Search Summary: ordered by increasing logloss\n",
       "    alpha    lambda    model_ids                    logloss\n",
       "--  -------  --------  ---------------------------  ---------\n",
       "    0.05     0.01      SBAloans_glm_grid7_model_4   0.393012\n",
       "    0.1      0.01      SBAloans_glm_grid7_model_2   0.393179\n",
       "    0.7      0.01      SBAloans_glm_grid7_model_7   0.396774\n",
       "    0.9      0.01      SBAloans_glm_grid7_model_15  0.398189\n",
       "    0.05     0.05      SBAloans_glm_grid7_model_6   0.400877\n",
       "    0.1      0.05      SBAloans_glm_grid7_model_16  0.402788\n",
       "    0.05     0.1       SBAloans_glm_grid7_model_12  0.410621\n",
       "    0.5      0.05      SBAloans_glm_grid7_model_17  0.424025\n",
       "    0.05     0.3       SBAloans_glm_grid7_model_10  0.438075\n",
       "    0.4      0.1       SBAloans_glm_grid7_model_1   0.445324\n",
       "    0.05     0.4       SBAloans_glm_grid7_model_13  0.446353\n",
       "    0.2      0.2       SBAloans_glm_grid7_model_9   0.452595\n",
       "    0.1      0.4       SBAloans_glm_grid7_model_8   0.457642\n",
       "    0.3      0.4       SBAloans_glm_grid7_model_11  0.464082\n",
       "    0.5      0.4       SBAloans_glm_grid7_model_14  0.464082\n",
       "    0.9      0.4       SBAloans_glm_grid7_model_3   0.464082\n",
       "    0.4      0.2       SBAloans_glm_grid7_model_5   0.464082"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_grid = H2OGridSearch(model=H2OGeneralizedLinearEstimator,\n",
    "                     hyper_params=glm_hyper_params,\n",
    "                     search_criteria=grid_search_criteria,\n",
    "                     grid_id=\"SBAloans_glm_grid7\")\n",
    "\n",
    "glm_grid.train(x=predictors, y=response, training_frame=X_train_h2o, validation_frame = X_valid_h2o,\n",
    "              nfolds = 2, family = \"binomial\", fold_assignment=\"auto\", seed=142, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "492ae40d-e087-4ae0-aa10-d733463663f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-4.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-4 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-4 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-4 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table th,\n",
       "#h2o-table-4 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Hyper-Parameter Search Summary: ordered by decreasing auc</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>alpha</th>\n",
       "<th>lambda</th>\n",
       "<th>model_ids</th>\n",
       "<th>auc</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>0.1</td>\n",
       "<td>0.01</td>\n",
       "<td>SBAloans_glm_grid7_model_2</td>\n",
       "<td>0.7710537</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.05</td>\n",
       "<td>0.01</td>\n",
       "<td>SBAloans_glm_grid7_model_4</td>\n",
       "<td>0.7709979</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.7</td>\n",
       "<td>0.01</td>\n",
       "<td>SBAloans_glm_grid7_model_7</td>\n",
       "<td>0.7690640</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.9</td>\n",
       "<td>0.01</td>\n",
       "<td>SBAloans_glm_grid7_model_15</td>\n",
       "<td>0.7685365</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.1</td>\n",
       "<td>0.05</td>\n",
       "<td>SBAloans_glm_grid7_model_16</td>\n",
       "<td>0.7674197</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.05</td>\n",
       "<td>0.05</td>\n",
       "<td>SBAloans_glm_grid7_model_6</td>\n",
       "<td>0.7672548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.05</td>\n",
       "<td>0.1</td>\n",
       "<td>SBAloans_glm_grid7_model_12</td>\n",
       "<td>0.7649207</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.05</td>\n",
       "<td>0.3</td>\n",
       "<td>SBAloans_glm_grid7_model_10</td>\n",
       "<td>0.7639241</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.05</td>\n",
       "<td>0.4</td>\n",
       "<td>SBAloans_glm_grid7_model_13</td>\n",
       "<td>0.7621514</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.5</td>\n",
       "<td>0.05</td>\n",
       "<td>SBAloans_glm_grid7_model_17</td>\n",
       "<td>0.7515496</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.1</td>\n",
       "<td>0.4</td>\n",
       "<td>SBAloans_glm_grid7_model_8</td>\n",
       "<td>0.7324403</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.4</td>\n",
       "<td>0.1</td>\n",
       "<td>SBAloans_glm_grid7_model_1</td>\n",
       "<td>0.7299298</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.2</td>\n",
       "<td>0.2</td>\n",
       "<td>SBAloans_glm_grid7_model_9</td>\n",
       "<td>0.7297503</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.3</td>\n",
       "<td>0.4</td>\n",
       "<td>SBAloans_glm_grid7_model_11</td>\n",
       "<td>0.4986614</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.5</td>\n",
       "<td>0.4</td>\n",
       "<td>SBAloans_glm_grid7_model_14</td>\n",
       "<td>0.4986614</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.9</td>\n",
       "<td>0.4</td>\n",
       "<td>SBAloans_glm_grid7_model_3</td>\n",
       "<td>0.4986614</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.4</td>\n",
       "<td>0.2</td>\n",
       "<td>SBAloans_glm_grid7_model_5</td>\n",
       "<td>0.4986614</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "Hyper-Parameter Search Summary: ordered by decreasing auc\n",
       "    alpha    lambda    model_ids                    auc\n",
       "--  -------  --------  ---------------------------  --------\n",
       "    0.1      0.01      SBAloans_glm_grid7_model_2   0.771054\n",
       "    0.05     0.01      SBAloans_glm_grid7_model_4   0.770998\n",
       "    0.7      0.01      SBAloans_glm_grid7_model_7   0.769064\n",
       "    0.9      0.01      SBAloans_glm_grid7_model_15  0.768537\n",
       "    0.1      0.05      SBAloans_glm_grid7_model_16  0.76742\n",
       "    0.05     0.05      SBAloans_glm_grid7_model_6   0.767255\n",
       "    0.05     0.1       SBAloans_glm_grid7_model_12  0.764921\n",
       "    0.05     0.3       SBAloans_glm_grid7_model_10  0.763924\n",
       "    0.05     0.4       SBAloans_glm_grid7_model_13  0.762151\n",
       "    0.5      0.05      SBAloans_glm_grid7_model_17  0.75155\n",
       "    0.1      0.4       SBAloans_glm_grid7_model_8   0.73244\n",
       "    0.4      0.1       SBAloans_glm_grid7_model_1   0.72993\n",
       "    0.2      0.2       SBAloans_glm_grid7_model_9   0.72975\n",
       "    0.3      0.4       SBAloans_glm_grid7_model_11  0.498661\n",
       "    0.5      0.4       SBAloans_glm_grid7_model_14  0.498661\n",
       "    0.9      0.4       SBAloans_glm_grid7_model_3   0.498661\n",
       "    0.4      0.2       SBAloans_glm_grid7_model_5   0.498661"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the grid results, sorted by validation AUCPR\n",
    "gridperf1 = glm_grid.get_grid(sort_by='auc', decreasing=True)\n",
    "gridperf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d9a6586-88b8-42b7-93db-9975f1749cd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model performance (AUC) on test dataset: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7693238928789832"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab the top model, chosen by validation AUC\n",
    "best_grid = gridperf1.models[0]\n",
    "\n",
    "# Now let's evaluate the model performance on a test set\n",
    "# so we get an honest estimate of top model performance\n",
    "best_grid_perf = best_grid.model_performance(X_test_h2o)\n",
    "\n",
    "print(\"Best Model performance (AUC) on test dataset: \")\n",
    "best_grid_perf.auc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa421168-d861-4985-b6fc-7124204bf0eb",
   "metadata": {},
   "source": [
    "### What is the best set of parameters for the logistic regression model using AUC metric?\n",
    "    The best parameters are an alpha value of 0.1, and a lambda value of 0.01\n",
    "### What is the best model performance (AUC) on the X_valid_h2o validation dataset?\n",
    "    Validation AUC value of 0.7710537 for SBAloans_glm_grid7_model_2\n",
    "### What is the best model performance (AUC) on a test dataset?\n",
    "    Test AUC value is 0.7693239\n",
    "### Produce Confusion Matrix using best F1 probability threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1774c590-2aed-4aec-8eb7-1675054ab262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-5.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-5 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-5 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-5 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table th,\n",
       "#h2o-table-5 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.21630599656544539</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>105438.0</td>\n",
       "<td>26621.0</td>\n",
       "<td>0.2016</td>\n",
       "<td> (26621.0/132059.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>11778.0</td>\n",
       "<td>16214.0</td>\n",
       "<td>0.4208</td>\n",
       "<td> (11778.0/27992.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>117216.0</td>\n",
       "<td>42835.0</td>\n",
       "<td>0.2399</td>\n",
       "<td> (38399.0/160051.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.21630599656544539\n",
       "       0       1      Error    Rate\n",
       "-----  ------  -----  -------  ------------------\n",
       "0      105438  26621  0.2016   (26621.0/132059.0)\n",
       "1      11778   16214  0.4208   (11778.0/27992.0)\n",
       "Total  117216  42835  0.2399   (38399.0/160051.0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_grid_perf.confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9512ee99-48ca-422d-aecf-187ef0abe98d",
   "metadata": {},
   "source": [
    "### In general, an AUC of 0.5 suggests no discrimination (i.e., ability to diagnose patients with and without the disease or condition based on the test), 0.7 to 0.8 is considered acceptable. \n",
    "### Additionally, The AUC is meaningful as a diagnostic test only when it is > 0.5. The larger the value, the better the overall performance of the test.\n",
    "### Hence, an auc value of 0.7711 for logistic regression is good for the data set given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67749391-d797-4526-8fb7-c7caac3f5ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a14a37-1367-4b3e-b3e9-2e89032c9a00",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **PROJECT 1 REPORT/CONCLUSION:** </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4171d3b-cd20-40f7-b43a-8d1370ab9ee9",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> **Summary of your work:** </span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d6f966-6726-40a6-b8aa-29b60c5ac8a0",
   "metadata": {},
   "source": [
    "- I started the project by loading the data set as required and cleaning up the data as needed. Most of the code is commented on and/or markdown cells have been used to further explain my ideas. \n",
    "- There's no unnecessary code or text in all files, and any output is there because I deemed it would be necessary to understand my work. As such, things were kept as brief and succinct as possible.\n",
    "- For this project, I used a target encoder for categorical columns and a Standard scaler to standardize numerical columns\n",
    "- I then trained a logistic regression Sklearn model and a GLM binomial model using H2O.\n",
    "- For logistic regression using Sklearn:\n",
    "  - param_grid = [    \n",
    "    {'penalty' : ['l2'],\n",
    "    'solver' : ['lbfgs','newton-cg','sag','saga'],\n",
    "     'C': [10, 1.0, 0.1, 0.01],\n",
    "    'max_iter' : [100, 150, 175, 200, 250]\n",
    "    }]\n",
    "  - Total number of combinations for tuning the model: 1 X 4 X 4 X 5 = 80 combinations\n",
    "- For GLM modeling using H2O:\n",
    "  - glm_hyper_params = { 'alpha': [0.05,0.1,0.2,0.3,0.4, 0.5, 0.6, 0.7, 0.9], \n",
    "                     'lambda': [0.1,0.05,0.01, 0.2,0.3,0.4,0.5]}\n",
    "  - Total number of combinations for tuning the model: 9 X 7 = 63 combinations.\n",
    "  - Number of folds = 2, so 63/2 = 41 unique models\n",
    "- F1 score and AUC were included in the model results for the logistic regression sklearn model, whereas only the AUC metric was used for the H2O GLM model.\n",
    "- Then a train_model function was created to export the ipynb file as a pkl file containing the following artifacts:\n",
    "  - artifacts_dict = {\n",
    "        \"model\": clf,\n",
    "        \"categorical_columns\": categorical_columns,\n",
    "        \"numerical_variables\" : numerical_variables,\n",
    "        \"StandardScaler\": StandardScaler,\n",
    "        \"columns_to_train\":columns_to_train,\n",
    "        \"target_encoder\" : target_encoder,\n",
    "        \"threshold\": threshold\n",
    "    }\n",
    "- Lastly, in a new ipynb notebook, a scaling function was created to evaluate the results for the SBA_loans_project_1_holdout_students_valid dataset\n",
    "- As required, the submission has been packaged into a single zip file called Project1_Aishwarya_Adiki_axa180100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d701e4c-d72e-4d1a-927d-b82f6c35f926",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> **Summary of your findings and model performance:** </span>\n",
    "- For logistic regression using sklearn, quite a few warnings occurred due to the discrepancy between the type of model it was and the number of interactions it required. These warnings occurred due to non-convergence issues, but they were not errors. Probably occurred due to depracation\n",
    "- The probability threshold for logistic regression was found to be 0.9.\n",
    "- **Logistic Regression using Sklearn:**\n",
    "  - Best Parameters: {'C': 10, 'max_iter': 200, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
    "  - Best F1 Score: 0.8348609718577\n",
    "  - Confusion Matrix:\n",
    "     [128691   3368]\n",
    "     [ 23150   4842]\n",
    "  - AUC Score:  0.7702116835434315\n",
    "  - From this, we can see that the best parameters give us the F1 score of 0.83486. The F1 score ranges between 0 and 1, with 0 denoting the lowest possible result and 1 denoting a flawless result, meaning that the model accurately predicted each label. A high F1 score generally indicates a well-balanced performance, demonstrating that the model can concurrently attain high precision and high recall.\n",
    "  - Therefore an F1 Score of 0.83486 can be considered good. Furthermore, the AUC is 0.77021, which is moderately good and feasible as well\n",
    "- **GLM model using H2O:**\n",
    "  - Since there are only two levels (0 or 1) in the target/response column of \"MIS_Status\", I used binomial family classification to train the model using the hyperparameters mentioned earlier in the report.\n",
    "  - Hyper-Parameter Search Summary was ordered by increasing logloss and decreasing AUC. I considered the AUC metric as it was more appropriate for the imbalanced datasets provided to me\n",
    "  - The best parameters were an alpha value of 0.1, and a lambda value of 0.01 with a validation AUC value of 0.7710537 for SBAloans_glm_grid7_model_2 as shown in cell output above\n",
    "  - Though not shown in this notebook, I went to try a family classification of Gaussian and Poisson, but they yielded lower AUC values. Hence I decided to go with binomial GLM in the end.\n",
    "  The Test dataset's AUC value was 0.7693239, which was very close to the validation AUC value of 0.7710537. This shows that the modeling was done as accurately as possible.\n",
    "  - Additionally, I also produced a Confusion Matrix using the best F1 probability threshold, which is as follows:\n",
    "  - Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.21630599656544539\n",
    "  - To look at the whole matrix, please scroll to the appropriate output cell.\n",
    "  - In general, an AUC of 0.5 suggests no discrimination (i.e., ability to diagnose patients with and without the disease or condition based on the test), 0.7 to 0.8 is considered acceptable.\n",
    "  - Additionally, The AUC is meaningful as a diagnostic test only when it is > 0.5. The larger the value, the better the overall performance of the test. Hence, an auc value of 0.7711 for a GLM model is good for the data set given.\n",
    "\n",
    "##### **Comparing the Sklearn model vs H2O model:**\n",
    "- After tuning **both models**, the best parameters for each yielded the **same AUC value of 0.771**.\n",
    "- This makes perfect sense because mathematically speaking Logistic regression is a binomial regression with the \"logistic\" link function.\n",
    "- Furthermore, this also demonstrates the consistency between the two models and goes to show that if trained right, we will get to the same answer regardless of using sklearn, h2o, or any other tool/library\n",
    "- For the scoring function, I decided to use the sklearn model only because I am more familiar with it. That is a personal bias rather than a computational one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576b7fa9-83d3-4529-9f73-1f68d5710641",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> **Summary of your recommendations:** </span>\n",
    "- I can make some recommendations based on sklearn's logistic regression model.\n",
    "  1. Based on Feature Importance Using Permutation Method bar plot, we can see that certain features are more important than others and naturally will have more impact on the MIS_Status ( 0 = loan has been written off as a loss, or 1 = Small Business Successfully paid off the loan)\n",
    "  2. City_trg: 0.007164799553475642, Bank_trg: 0.01966823075144796, RevLineCr_trg: 0.0014720724435752601, UrbanRural: 0.001989574156570902, GrAppv: 0.007818632810791534, SBA_Appv: 0.00863503924790638 are the 6 most important features according to the model.\n",
    "  3. The city that the small business is located in is very important in addition to whether that place is urban or rural. After all, the busier a city, the more likely the small business is likely to get customers. This means that they have a higher chance of making a profit and thereby paying off the loan (MIS_Status would become 1 for Paid in Full)\n",
    "  4. Furthermore, Small Business Loan Approval (SBA_Appv) and Bank name are also important. The higher the loan preapproval from a well-reputed bank the more likely that the small business can pay off the loan in the future. Big/popular banks thoroughly perform a financial and background check before handing out loans. This means that they likely won't give you a loan if you have bad financials or collaterals. The banks and loan pre-approvers want to make sure their loan is as safe as possible and likely to be returned.\n",
    "  5. Additionally, by looking at the **coefficient for NoEmp**, we can see that with every additional employee hired, the loan is less likely to be paid off. This could be due to the fact that hiring employees costs money and will increase the expenses of the small business. At the same time, a small business most likely needs to hire at least 1 or 2 employees to keep things running, so this might prove to be a dilemma for owners.\n",
    "  6. Likewise, the signs on the coefficients on variables BalanceGross (outstanding loan amount) and DisbursementGross (Loan Amount originally given to the Small business) tell us that as Balance Gross increases, the less likely the small business becomes to pay off the loan (leads to MIS_Status of 0).\n",
    "  7. Similarly, as the original DisbursementGross increases (meaning the small business took a very big loan to begin with), the likelihood that the small business pays off the loan decreases(leads to MIS_Status of 0).\n",
    " \n",
    "As such, for the reasons listed above, I recommend that a small business owner start their business in a booming, urban city. Furthermore, I would recommend that they not start a business until they have good financial statements and collaterals to show to the bank. This can ensure better interest rates, which means that the debt amount would decrease contingent upon the fact that loan payments are made in a timely manner. Additionally, I would recommend the small business start off with few employees and upsize or downsize on its workforce as needed to reduce annual business operation expenses. Lastly, I would recommend the business to take out only as much loan as is required. Sometimes, if the financial background of the borrower is good, the bank gets ready to approve as much as it possibly can. However, the business may not actually need all that money. So I suggest that business owners stay wary of this and not fall into the pothole of borrowing more than what's required. The more loan you have, the longer and harder it is to pay it off."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
